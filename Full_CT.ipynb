{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XuOSMsgitQGW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import argparse\n",
    "import datetime\n",
    "import sys\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import shutil\n",
    "import hashlib\n",
    "from torch import nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "from dsetsFullCT import TrainingLuna2dSegmentationDataset, Luna2dSegmentationDataset, PrepcacheLunaDataset, getCt\n",
    "from util import logging, enumerateWithEstimate\n",
    "from UDet import UDet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb3D88NFuOP2"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e09Iypx9whOJ"
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, n_classes=2, depth=5, wf=6, padding=False,  #原論文channel數是64，為2^6\n",
    "                 batch_norm=False, up_mode='upconv'):\n",
    "        \"\"\"\n",
    "        Implementation of\n",
    "        U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "        (Ronneberger et al., 2015)\n",
    "        https://arxiv.org/abs/1505.04597\n",
    "\n",
    "        Using the default arguments will yield the exact version used\n",
    "        in the original paper\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): number of input channels\n",
    "            n_classes (int): number of output channels\n",
    "            depth (int): depth of the network\n",
    "            wf (int): number of filters in the first layer is 2**wf\n",
    "            padding (bool): if True, apply padding such that the input shape\n",
    "                            is the same as the output.\n",
    "                            This may introduce artifacts\n",
    "            batch_norm (bool): Use BatchNorm after layers with an\n",
    "                               activation function\n",
    "            up_mode (str): one of 'upconv' or 'upsample'.\n",
    "                           'upconv' will use transposed convolutions for\n",
    "                           learned upsampling.\n",
    "                           'upsample' will use bilinear upsampling.\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        assert up_mode in ('upconv', 'upsample')\n",
    "        self.padding = padding\n",
    "        self.depth = depth\n",
    "        prev_channels = in_channels\n",
    "        self.down_path = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.down_path.append(UNetConvBlock(prev_channels, 2**(wf+i),\n",
    "                                                padding, batch_norm))\n",
    "            prev_channels = 2**(wf+i)\n",
    "\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.up_path.append(UNetUpBlock(prev_channels, 2**(wf+i), up_mode,\n",
    "                                            padding, batch_norm))\n",
    "            prev_channels = 2**(wf+i) #channel數會隨著down sampling增加，以2的倍數增加\n",
    "\n",
    "        self.last = nn.Conv2d(prev_channels, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        blocks = []\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            x = down(x)\n",
    "            if i != len(self.down_path)-1:\n",
    "                blocks.append(x)  #put the result in blocks, and to be a bridge to upsampleing\n",
    "                x = F.avg_pool2d(x, 2)  #做一次的avarage pooling, stride為2, kernel size 為2(大小砍半)\n",
    "\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i-1])\n",
    "\n",
    "        return self.last(x)\n",
    "\n",
    "class UNetConvBlock(nn.Module): #每一層都會做2次的convolution，kenrel size 都是3\n",
    "    def __init__(self, in_size, out_size, padding, batch_norm):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        block = []\n",
    "\n",
    "        block.append(nn.Conv2d(in_size, out_size, kernel_size=3,\n",
    "                               padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        # block.append(nn.LeakyReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        block.append(nn.Conv2d(out_size, out_size, kernel_size=3,\n",
    "                               padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        # block.append(nn.LeakyReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return out\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, up_mode, padding, batch_norm):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        if up_mode == 'upconv':\n",
    "            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2,\n",
    "                                         stride=2)\n",
    "        elif up_mode == 'upsample':\n",
    "            self.up = nn.Sequential(nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                                    nn.Conv2d(in_size, out_size, kernel_size=1))\n",
    "\n",
    "        self.conv_block = UNetConvBlock(in_size, out_size, padding, batch_norm)\n",
    "\n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[:, :, diff_y:(diff_y + target_size[0]), diff_x:(diff_x + target_size[1])]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "R4uR6voouQao"
   },
   "outputs": [],
   "source": [
    "class UNetWrapper(nn.Module):\n",
    "    def __init__(self, **kwargs): #kwarg is a dictionary containing all keyword arguments passed to the constructor\n",
    "        super().__init__()\n",
    "\n",
    "        # we will do batchnormalization first \n",
    "        self.input_batchnorm = nn.BatchNorm2d(kwargs['in_channels'])  #in kwarg, we have in_channels params to give the input channel\n",
    "        self.unet = UNet(**kwargs)\n",
    "        self.final = nn.Sigmoid() #use sigmoid to limit the output to 0,1\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        init_set = {\n",
    "            nn.Conv2d,\n",
    "            nn.Conv3d,\n",
    "            nn.ConvTranspose2d,\n",
    "            nn.ConvTranspose3d,\n",
    "            nn.Linear,\n",
    "        }\n",
    "        for m in self.modules():\n",
    "            if type(m) in init_set:\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight.data, mode='fan_out', nonlinearity='relu', a=0\n",
    "                )\n",
    "                if m.bias is not None:\n",
    "                    fan_in, fan_out = \\\n",
    "                        nn.init._calculate_fan_in_and_fan_out(m.weight.data)\n",
    "                    bound = 1 / math.sqrt(fan_out)\n",
    "                    nn.init.normal_(m.bias, -bound, bound)\n",
    "\n",
    "        # nn.init.constant_(self.unet.last.bias, -4)\n",
    "        # nn.init.constant_(self.unet.last.bias, 4)\n",
    "\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        bn_output = self.input_batchnorm(input_batch)\n",
    "        un_output = self.unet(bn_output)\n",
    "        fn_output = self.final(un_output)\n",
    "        return fn_output\n",
    "    \n",
    "class UDetWrapper(nn.Module):\n",
    "    def __init__(self, **kwargs): #kwarg is a dictionary containing all keyword arguments passed to the constructor\n",
    "        super().__init__()\n",
    "\n",
    "        # we will do batchnormalization first \n",
    "        self.input_batchnorm = nn.BatchNorm2d(kwargs['in_channels'])  #in kwarg, we have in_channels params to give the input channel\n",
    "        self.udet = UDet(**kwargs)\n",
    "        self.final = nn.Sigmoid() #use sigmoid to limit the output to 0,1\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        init_set = {\n",
    "            nn.Conv2d,\n",
    "            nn.Conv3d,\n",
    "            nn.ConvTranspose2d,\n",
    "            nn.ConvTranspose3d,\n",
    "            nn.Linear,\n",
    "        }\n",
    "        for m in self.modules():\n",
    "            if type(m) in init_set:\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight.data, mode='fan_out', nonlinearity='relu', a=0\n",
    "                )\n",
    "                if m.bias is not None:\n",
    "                    fan_in, fan_out = \\\n",
    "                        nn.init._calculate_fan_in_and_fan_out(m.weight.data)\n",
    "                    bound = 1 / math.sqrt(fan_out)\n",
    "                    nn.init.normal_(m.bias, -bound, bound)\n",
    "\n",
    "        # nn.init.constant_(self.unet.last.bias, -4)\n",
    "        # nn.init.constant_(self.unet.last.bias, 4)\n",
    "\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        bn_output = self.input_batchnorm(input_batch)\n",
    "        un_output = self.udet(bn_output)\n",
    "        fn_output = self.final(un_output)\n",
    "        return fn_output\n",
    "\n",
    "class SegmentationAugmentation(nn.Module):\n",
    "    def __init__(\n",
    "            self, flip=None, offset=None, scale=None, rotate=None, noise=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.flip = flip\n",
    "        self.offset = offset\n",
    "        self.scale = scale\n",
    "        self.rotate = rotate\n",
    "        self.noise = noise\n",
    "\n",
    "    def forward(self, input_g, label_g):\n",
    "        transform_t = self._build2dTransformMatrix()\n",
    "        transform_t = transform_t.expand(input_g.shape[0], -1, -1)  #對Index複製\n",
    "        transform_t = transform_t.to(input_g.device, torch.float32) #transform前兩行有關伸縮旋轉，最後一行有關平移\n",
    "        affine_t = F.affine_grid(transform_t[:,:2],\n",
    "                input_g.size(), align_corners=False)  #使用affine grid的原因是因為用grid可以減少對整張圖的運算量\n",
    "                                     #而且如果用原圖，可能會造成座標落在非整數格上，如此會讓圖型產生矩齒狀\n",
    "\n",
    "        augmented_input_g = F.grid_sample(input_g,\n",
    "                affine_t, padding_mode='border',\n",
    "                align_corners=False)\n",
    "        augmented_label_g = F.grid_sample(label_g.to(torch.float32),#grid sample只吃float，所以這裡轉float，但用同一個affine grid\n",
    "                affine_t, padding_mode='border',\n",
    "                align_corners=False)\n",
    "\n",
    "        if self.noise:\n",
    "            noise_t = torch.randn_like(augmented_input_g)\n",
    "            noise_t *= self.noise\n",
    "\n",
    "            augmented_input_g += noise_t\n",
    "\n",
    "        return augmented_input_g, augmented_label_g > 0.5 #把label改回成0,1\n",
    "\n",
    "    def _build2dTransformMatrix(self):\n",
    "        transform_t = torch.eye(3)  #建立一個3*3單位矩陣\n",
    "\n",
    "        for i in range(2):  #我們只有2D\n",
    "            if self.flip:\n",
    "                if random.random() > 0.5:\n",
    "                    transform_t[i,i] *= -1\n",
    "\n",
    "            if self.offset:\n",
    "                offset_float = self.offset\n",
    "                random_float = (random.random() * 2 - 1)\n",
    "                transform_t[2,i] = offset_float * random_float\n",
    "\n",
    "            if self.scale:\n",
    "                scale_float = self.scale\n",
    "                random_float = (random.random() * 2 - 1)\n",
    "                transform_t[i,i] *= 1.0 + scale_float * random_float\n",
    "\n",
    "        if self.rotate:\n",
    "            angle_rad = random.random() * math.pi * 2 #隨機弧度\n",
    "            s = math.sin(angle_rad) #轉角度\n",
    "            c = math.cos(angle_rad)\n",
    "\n",
    "            rotation_t = torch.tensor([\n",
    "                [c, -s, 0],\n",
    "                [s, c, 0],\n",
    "                [0, 0, 1]])\n",
    "\n",
    "            transform_t @= rotation_t #矩陣乘法\n",
    "\n",
    "        return transform_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsRW7wTH2ISQ"
   },
   "source": [
    "# Prepcache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PzMZ9d-Vov1j"
   },
   "outputs": [],
   "source": [
    "class LunaPrepCacheApp:\n",
    "    @classmethod\n",
    "    def __init__(self, sys_argv=None):\n",
    "        if sys_argv is None:\n",
    "            sys_argv = sys.argv[1:]\n",
    "\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--batch-size',\n",
    "            help='Batch size to use for training',\n",
    "            default=1024,\n",
    "            type=int,\n",
    "        )\n",
    "        parser.add_argument('--num-workers',\n",
    "            help='Number of worker processes for background data loading',\n",
    "            default=1, #8\n",
    "            type=int,\n",
    "        )\n",
    "        # parser.add_argument('--scaled',\n",
    "        #     help=\"Scale the CT chunks to square voxels.\",\n",
    "        #     default=False,\n",
    "        #     action='store_true',\n",
    "        # )\n",
    "\n",
    "        self.cli_args = parser.parse_args(sys_argv)\n",
    "\n",
    "    def main(self):\n",
    "        log.info(\"Starting {}, {}\".format(type(self).__name__, self.cli_args))\n",
    "\n",
    "        self.prep_dl = DataLoader(\n",
    "             PrepcacheLunaDataset(\n",
    "#                 # sortby_str='series_uid',\n",
    "             ),\n",
    "   \n",
    "            batch_size=self.cli_args.batch_size,\n",
    "            num_workers=self.cli_args.num_workers,\n",
    "        )\n",
    "\n",
    "        batch_iter = enumerateWithEstimate(\n",
    "            self.prep_dl,\n",
    "            \"Stuffing cache\",\n",
    "            start_ndx=self.prep_dl.num_workers,\n",
    "        )\n",
    "        for batch_ndx, batch_tup in batch_iter:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ymn03JNItty_"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.epsilon = 1e-5\n",
    "    \n",
    "    def forward(self, predict, target):\n",
    "        assert predict.size() == target.size(), \"the size of predict and target must be equal.\"\n",
    "        num = predict.size(0)\n",
    "        \n",
    "        pre = torch.sigmoid(predict).view(num, -1)\n",
    "        tar = target.view(num, -1)\n",
    "        \n",
    "        intersection = (pre * tar).sum(-1).sum()  #利用预测值与标签相乘当作交集\n",
    "        union = (pre + tar).sum(-1).sum()\n",
    "        \n",
    "        score = 1 - 2 * (intersection + self.epsilon) / (union + self.epsilon)\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3wyfcVhgykNH"
   },
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "# log.setLevel(logging.WARN)\n",
    "# log.setLevel(logging.INFO)\n",
    "log.setLevel(logging.DEBUG)\n",
    "METRICS_LOSS_NDX = 1\n",
    "METRICS_TP_NDX = 7\n",
    "METRICS_FN_NDX = 8\n",
    "METRICS_FP_NDX = 9\n",
    "\n",
    "METRICS_SIZE = 10\n",
    "class SegmentationTrainingApp:\n",
    "    def __init__(self, sys_argv=None):\n",
    "        if sys_argv is None:\n",
    "            sys_argv = sys.argv[1:]\n",
    "\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--batch-size',\n",
    "            help='Batch size to use for training',\n",
    "            default=16,\n",
    "            type=int,\n",
    "        )\n",
    "        parser.add_argument('--num-workers',\n",
    "            help='Number of worker processes for background data loading',\n",
    "            default=8,\n",
    "            type=int,\n",
    "        )\n",
    "        parser.add_argument('--epochs',\n",
    "            help='Number of epochs to train for',\n",
    "            default=1,\n",
    "            type=int,\n",
    "        )\n",
    "\n",
    "        parser.add_argument('--augmented',\n",
    "            help=\"Augment the training data.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "        parser.add_argument('--augment-flip',\n",
    "            help=\"Augment the training data by randomly flipping the data left-right, up-down, and front-back.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "        parser.add_argument('--augment-offset',\n",
    "            help=\"Augment the training data by randomly offsetting the data slightly along the X and Y axes.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "        parser.add_argument('--augment-scale',\n",
    "            help=\"Augment the training data by randomly increasing or decreasing the size of the candidate.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "        parser.add_argument('--augment-rotate',\n",
    "            help=\"Augment the training data by randomly rotating the data around the head-foot axis.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "        parser.add_argument('--augment-noise',\n",
    "            help=\"Augment the training data by randomly adding noise to the data.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "\n",
    "        parser.add_argument('--tb-prefix',\n",
    "            default='udet',\n",
    "            help=\"Data prefix to use for Tensorboard run. Defaults to chapter.\",\n",
    "        )\n",
    "\n",
    "        parser.add_argument('comment',\n",
    "            help=\"Comment suffix for Tensorboard run.\",\n",
    "            nargs='?',\n",
    "            default='none',\n",
    "        )\n",
    "\n",
    "        self.cli_args = parser.parse_args(sys_argv)\n",
    "        self.time_str = datetime.datetime.now().strftime('%Y-%m-%d_%H.%M.%S')\n",
    "        self.totalTrainingSamples_count = 0\n",
    "        self.trn_writer = None\n",
    "        self.val_writer = None\n",
    "\n",
    "        #augumentation設定的值\n",
    "        self.augmentation_dict = {}\n",
    "        if self.cli_args.augmented or self.cli_args.augment_flip:\n",
    "            self.augmentation_dict['flip'] = True\n",
    "        if self.cli_args.augmented or self.cli_args.augment_offset:\n",
    "            self.augmentation_dict['offset'] = 0.03\n",
    "        if self.cli_args.augmented or self.cli_args.augment_scale:\n",
    "            self.augmentation_dict['scale'] = 0.2\n",
    "        if self.cli_args.augmented or self.cli_args.augment_rotate:\n",
    "            self.augmentation_dict['rotate'] = True\n",
    "        if self.cli_args.augmented or self.cli_args.augment_noise:\n",
    "            self.augmentation_dict['noise'] = 25.0\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "\n",
    "        self.segmentation_model, self.augmentation_model = self.initModel()\n",
    "        self.optimizer = self.initOptimizer()\n",
    "\n",
    "\n",
    "    def initModel(self):\n",
    "        segmentation_model = UNetWrapper(\n",
    "            in_channels=7,\n",
    "            n_classes=1,\n",
    "            depth=2,  #how deep the U go\n",
    "            wf=6,   #2^4 filter\n",
    "            padding=True, #padding so that we get the output size as input size\n",
    "            batch_norm=True,\n",
    "            up_mode='upconv', #use  nn.ConvTranspose2d\n",
    "        )\n",
    "\n",
    "        augmentation_model = SegmentationAugmentation(**self.augmentation_dict)\n",
    "\n",
    "        if self.use_cuda:\n",
    "            log.info(\"Using CUDA; {} devices.\".format(torch.cuda.device_count()))\n",
    "            if torch.cuda.device_count() > 1: #parallel data if we have much device\n",
    "                segmentation_model = nn.DataParallel(segmentation_model)\n",
    "                augmentation_model = nn.DataParallel(augmentation_model)\n",
    "            segmentation_model = segmentation_model.to(self.device)\n",
    "            augmentation_model = augmentation_model.to(self.device)\n",
    "\n",
    "        return segmentation_model, augmentation_model #回傳unet wrapper和augmentation\n",
    "\n",
    "    def initOptimizer(self):\n",
    "        return Adam(self.segmentation_model.parameters(), lr=0.001, betas=(0.99,0.999), weight_decay=1e-6)\n",
    "        # return SGD(self.segmentation_model.parameters(), lr=0.001, momentum=0.99)\n",
    "\n",
    "\n",
    "    def initTrainDl(self):\n",
    "        train_ds = TrainingLuna2dSegmentationDataset(\n",
    "            val_stride=10,\n",
    "            isValSet_bool=False,\n",
    "            contextSlices_count=3,\n",
    "        )\n",
    "\n",
    "        batch_size = self.cli_args.batch_size\n",
    "        if self.use_cuda:\n",
    "            batch_size *= torch.cuda.device_count()\n",
    "\n",
    "        train_dl = DataLoader(\n",
    "            train_ds,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=self.cli_args.num_workers,\n",
    "            pin_memory=self.use_cuda,\n",
    "        )\n",
    "\n",
    "        return train_dl\n",
    "\n",
    "    def initValDl(self):\n",
    "        val_ds = Luna2dSegmentationDataset(\n",
    "            val_stride=10,\n",
    "            isValSet_bool=True,\n",
    "            contextSlices_count=3,\n",
    "        )\n",
    "\n",
    "        batch_size = self.cli_args.batch_size\n",
    "        if self.use_cuda:\n",
    "            batch_size *= torch.cuda.device_count()\n",
    "\n",
    "        val_dl = DataLoader(\n",
    "            val_ds,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=self.cli_args.num_workers,\n",
    "            pin_memory=self.use_cuda,\n",
    "        )\n",
    "\n",
    "        return val_dl\n",
    "\n",
    "    def initTensorboardWriters(self):\n",
    "        if self.trn_writer is None:\n",
    "            log_dir = os.path.join('runs', self.cli_args.tb_prefix, self.time_str)\n",
    "\n",
    "            self.trn_writer = SummaryWriter(\n",
    "                log_dir=log_dir + '_trn_seg_' + self.cli_args.comment)\n",
    "            self.val_writer = SummaryWriter(\n",
    "                log_dir=log_dir + '_val_seg_' + self.cli_args.comment)\n",
    "\n",
    "    def main(self):\n",
    "        log.info(\"Starting {}, {}\".format(type(self).__name__, self.cli_args))\n",
    "\n",
    "        train_dl = self.initTrainDl()\n",
    "        val_dl = self.initValDl()\n",
    "\n",
    "        best_score = 0.0\n",
    "        self.validation_cadence = 5\n",
    "        for epoch_ndx in range(1, self.cli_args.epochs + 1):\n",
    "            log.info(\"Epoch {} of {}, {}/{} batches of size {}*{}\".format(\n",
    "                epoch_ndx,\n",
    "                self.cli_args.epochs,\n",
    "                len(train_dl),\n",
    "                len(val_dl),\n",
    "                self.cli_args.batch_size,\n",
    "                (torch.cuda.device_count() if self.use_cuda else 1),\n",
    "            ))\n",
    "\n",
    "            trnMetrics_t = self.doTraining(epoch_ndx, train_dl)\n",
    "            self.logMetrics(epoch_ndx, 'trn', trnMetrics_t)\n",
    "\n",
    "            if epoch_ndx == 1 or epoch_ndx % self.validation_cadence == 0:\n",
    "                # if validation is wanted\n",
    "                valMetrics_t = self.doValidation(epoch_ndx, val_dl)\n",
    "                score = self.logMetrics(epoch_ndx, 'val', valMetrics_t)\n",
    "                best_score = max(score, best_score)\n",
    "\n",
    "                self.saveModel('seg', epoch_ndx, score == best_score)\n",
    "\n",
    "                self.logImages(epoch_ndx, 'trn', train_dl)\n",
    "                self.logImages(epoch_ndx, 'val', val_dl)\n",
    "\n",
    "        self.trn_writer.close()\n",
    "        self.val_writer.close()\n",
    "\n",
    "    def doTraining(self, epoch_ndx, train_dl):\n",
    "        trnMetrics_g = torch.zeros(METRICS_SIZE, len(train_dl.dataset), device=self.device)\n",
    "        self.segmentation_model.train()\n",
    "        train_dl.dataset.shuffleSamples()\n",
    "\n",
    "        batch_iter = enumerateWithEstimate(\n",
    "            train_dl,\n",
    "            \"E{} Training\".format(epoch_ndx),\n",
    "            start_ndx=train_dl.num_workers,\n",
    "        )\n",
    "        for batch_ndx, batch_tup in batch_iter:\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            loss_var = self.computeBatchLoss(batch_ndx, batch_tup, train_dl.batch_size, trnMetrics_g)\n",
    "            loss_var.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "        self.totalTrainingSamples_count += trnMetrics_g.size(1)\n",
    "\n",
    "        return trnMetrics_g.to('cpu')\n",
    "\n",
    "    def doValidation(self, epoch_ndx, val_dl):\n",
    "        with torch.no_grad():\n",
    "            valMetrics_g = torch.zeros(METRICS_SIZE, len(val_dl.dataset), device=self.device)\n",
    "            self.segmentation_model.eval()\n",
    "            batch_iter = enumerateWithEstimate(\n",
    "                val_dl,\n",
    "                \"E{} Validation \".format(epoch_ndx),\n",
    "                start_ndx=val_dl.num_workers,\n",
    "            )\n",
    "            for batch_ndx, batch_tup in batch_iter:\n",
    "                self.computeBatchLoss(batch_ndx, batch_tup, val_dl.batch_size, valMetrics_g)\n",
    "\n",
    "        return valMetrics_g.to('cpu')\n",
    "\n",
    "    def computeBatchLoss(self, batch_ndx, batch_tup, batch_size, metrics_g,\n",
    "                         classificationThreshold=0.5):\n",
    "        input_t, label_t, series_list, _slice_ndx_list = batch_tup\n",
    "\n",
    "        input_g = input_t.to(self.device, non_blocking=True)\n",
    "        label_g = label_t.to(self.device, non_blocking=True)\n",
    "\n",
    "        if self.segmentation_model.training and self.augmentation_dict:\n",
    "            input_g, label_g = self.augmentation_model(input_g, label_g)\n",
    "\n",
    "        prediction_g = self.segmentation_model(input_g)\n",
    "        \n",
    "        pos_weight = torch.tensor([1000.0]).to(self.device, non_blocking=True)\n",
    "        \n",
    "        \n",
    "        # loss = DiceLoss()\n",
    "        # DLoss = criterion(prediction_g, label_g.to(torch.float))\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        BCELoss = criterion(prediction_g, label_g.to(torch.float))\n",
    "        # fnLoss_g = criterion(prediction_g * ~label_g, label_g.to(torch.float))\n",
    "        # print(BCELoss)\n",
    "\n",
    "        # diceLoss_g = self.diceLoss(prediction_g, label_g)\n",
    "        # fnLoss_g = self.diceLoss(prediction_g * label_g, label_g) #只關心ground truth為true的部分\n",
    "#         # print(diceLoss_g.mean())\n",
    "#         # print(fnLoss_g)\n",
    "#         # print(diceLoss_g + fnLoss_g * 8)\n",
    "#         # print()\n",
    "\n",
    "        start_ndx = batch_ndx * batch_size\n",
    "        end_ndx = start_ndx + input_t.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictionBool_g = (prediction_g[:, 0:1]\n",
    "                                > classificationThreshold).to(torch.float32)\n",
    "\n",
    "            tp = (     predictionBool_g *  label_g).sum(dim=[1,2,3])\n",
    "            fn = ((1 - predictionBool_g) *  label_g).sum(dim=[1,2,3])\n",
    "            fp = (     predictionBool_g * (~label_g)).sum(dim=[1,2,3])\n",
    "\n",
    "            metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = BCELoss\n",
    "            # metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = diceLoss_g + fnLoss_g * 8\n",
    "            metrics_g[METRICS_TP_NDX, start_ndx:end_ndx] = tp\n",
    "            metrics_g[METRICS_FN_NDX, start_ndx:end_ndx] = fn\n",
    "            metrics_g[METRICS_FP_NDX, start_ndx:end_ndx] = fp\n",
    "        return BCELoss\n",
    "        # return BCELoss\n",
    "            \n",
    "        # return diceLoss_g.mean()\n",
    "\n",
    "        # return diceLoss_g.mean() + fnLoss_g.mean() * 8  #loss 的權重:positive pixel是negative的8倍, we should expect a large number of false positives in general\n",
    "        \n",
    "\n",
    "    def diceLoss(self, prediction_g, label_g, epsilon=1): #如果大部分的pixel是false，用dice會比較精準\n",
    "        diceLabel_g = label_g.sum(dim=[1,2,3])  #將所有mask裡計為nodule的點加起來(我們的dataset是4維, 後3維是index, row, column)\n",
    "        dicePrediction_g = prediction_g.sum(dim=[1,2,3])\n",
    "        diceCorrect_g = (prediction_g * label_g).sum(dim=[1,2,3]) #預測正確的總量\n",
    "\n",
    "        diceRatio_g = (2 * diceCorrect_g + epsilon) \\\n",
    "            / (dicePrediction_g + diceLabel_g + epsilon)  #epsilon避免其值為0\n",
    "\n",
    "        return 1 - diceRatio_g  #為了最小化，要用1去扣\n",
    "\n",
    "\n",
    "    def logImages(self, epoch_ndx, mode_str, dl):\n",
    "        self.segmentation_model.eval()\n",
    "\n",
    "        images = sorted(dl.dataset.series_list)[:12]\n",
    "        for series_ndx, series_uid in enumerate(images):\n",
    "            ct = getCt(series_uid)\n",
    "\n",
    "            for slice_ndx in range(6):\n",
    "                ct_ndx = slice_ndx * (ct.hu_a.shape[0] - 1) // 5\n",
    "                sample_tup = dl.dataset.getitem_fullSlice(series_uid, ct_ndx)\n",
    "\n",
    "                ct_t, label_t, series_uid, ct_ndx = sample_tup\n",
    "\n",
    "                input_g = ct_t.to(self.device).unsqueeze(0)\n",
    "                label_g = pos_g = label_t.to(self.device).unsqueeze(0)\n",
    "\n",
    "                prediction_g = self.segmentation_model(input_g)[0]\n",
    "                prediction_a = prediction_g.to('cpu').detach().numpy()[0] > 0.5\n",
    "                label_a = label_g.cpu().numpy()[0][0] > 0.5\n",
    "\n",
    "                ct_t[:-1,:,:] /= 2000\n",
    "                ct_t[:-1,:,:] += 0.5\n",
    "\n",
    "                ctSlice_a = ct_t[dl.dataset.contextSlices_count].numpy()\n",
    "\n",
    "                image_a = np.zeros((512, 512, 3), dtype=np.float32)\n",
    "                image_a[:,:,:] = ctSlice_a.reshape((512,512,1))\n",
    "                image_a[:,:,0] += prediction_a & (1 - label_a)\n",
    "                image_a[:,:,0] += (1 - prediction_a) & label_a\n",
    "                image_a[:,:,1] += ((1 - prediction_a) & label_a) * 0.5\n",
    "\n",
    "                image_a[:,:,1] += prediction_a & label_a\n",
    "                image_a *= 0.5\n",
    "                image_a.clip(0, 1, image_a)\n",
    "\n",
    "                writer = getattr(self, mode_str + '_writer')\n",
    "                writer.add_image(\n",
    "                    f'{mode_str}/{series_ndx}_prediction_{slice_ndx}',\n",
    "                    image_a,\n",
    "                    self.totalTrainingSamples_count,\n",
    "                    dataformats='HWC',\n",
    "                )\n",
    "\n",
    "                if epoch_ndx == 1:\n",
    "                    image_a = np.zeros((512, 512, 3), dtype=np.float32)\n",
    "                    image_a[:,:,:] = ctSlice_a.reshape((512,512,1))\n",
    "                    # image_a[:,:,0] += (1 - label_a) & lung_a # Red\n",
    "                    image_a[:,:,1] += label_a  # Green\n",
    "                    # image_a[:,:,2] += neg_a  # Blue\n",
    "\n",
    "                    image_a *= 0.5\n",
    "                    image_a[image_a < 0] = 0\n",
    "                    image_a[image_a > 1] = 1\n",
    "                    writer.add_image(\n",
    "                        '{}/{}_label_{}'.format(\n",
    "                            mode_str,\n",
    "                            series_ndx,\n",
    "                            slice_ndx,\n",
    "                        ),\n",
    "                        image_a,\n",
    "                        self.totalTrainingSamples_count,\n",
    "                        dataformats='HWC',\n",
    "                    )\n",
    "                # This flush prevents TB from getting confused about which\n",
    "                # data item belongs where.\n",
    "                writer.flush()\n",
    "\n",
    "    def logMetrics(self, epoch_ndx, mode_str, metrics_t):\n",
    "        log.info(\"E{} {}\".format(\n",
    "            epoch_ndx,\n",
    "            type(self).__name__,\n",
    "        ))\n",
    "\n",
    "        metrics_a = metrics_t.detach().numpy()\n",
    "        sum_a = metrics_a.sum(axis=1)\n",
    "        assert np.isfinite(metrics_a).all()\n",
    "\n",
    "        allLabel_count = sum_a[METRICS_TP_NDX] + sum_a[METRICS_FN_NDX]\n",
    "\n",
    "        metrics_dict = {}\n",
    "        metrics_dict['loss/all'] = metrics_a[METRICS_LOSS_NDX].mean()\n",
    "\n",
    "        metrics_dict['percent_all/tp'] = \\\n",
    "            sum_a[METRICS_TP_NDX] / (allLabel_count or 1) * 100\n",
    "        metrics_dict['percent_all/fn'] = \\\n",
    "            sum_a[METRICS_FN_NDX] / (allLabel_count or 1) * 100\n",
    "        metrics_dict['percent_all/fp'] = \\\n",
    "            sum_a[METRICS_FP_NDX] / (allLabel_count or 1) * 100\n",
    "\n",
    "\n",
    "        precision = metrics_dict['pr/precision'] = sum_a[METRICS_TP_NDX] \\\n",
    "            / ((sum_a[METRICS_TP_NDX] + sum_a[METRICS_FP_NDX]) or 1)\n",
    "        recall    = metrics_dict['pr/recall']    = sum_a[METRICS_TP_NDX] \\\n",
    "            / ((sum_a[METRICS_TP_NDX] + sum_a[METRICS_FN_NDX]) or 1)\n",
    "\n",
    "        metrics_dict['pr/f1_score'] = 2 * (precision * recall) \\\n",
    "            / ((precision + recall) or 1)\n",
    "\n",
    "        log.info((\"E{} {:8} \"\n",
    "                 + \"{loss/all:.4f} loss, \"\n",
    "                 + \"{pr/precision:.4f} precision, \"\n",
    "                 + \"{pr/recall:.4f} recall, \"\n",
    "                 + \"{pr/f1_score:.4f} f1 score\"\n",
    "                  ).format(\n",
    "            epoch_ndx,\n",
    "            mode_str,\n",
    "            **metrics_dict,\n",
    "        ))\n",
    "        log.info((\"E{} {:8} \"\n",
    "                  + \"{loss/all:.4f} loss, \"\n",
    "                  + \"{percent_all/tp:-5.1f}% tp, {percent_all/fn:-5.1f}% fn, {percent_all/fp:-9.1f}% fp\"\n",
    "        ).format(\n",
    "            epoch_ndx,\n",
    "            mode_str + '_all',\n",
    "            **metrics_dict,\n",
    "        ))\n",
    "\n",
    "        self.initTensorboardWriters()\n",
    "        writer = getattr(self, mode_str + '_writer')\n",
    "\n",
    "        prefix_str = 'seg_'\n",
    "\n",
    "        for key, value in metrics_dict.items():\n",
    "            writer.add_scalar(prefix_str + key, value, self.totalTrainingSamples_count)\n",
    "\n",
    "        writer.flush()\n",
    "\n",
    "        score = metrics_dict['pr/recall']\n",
    "\n",
    "        return score\n",
    "\n",
    "    def saveModel(self, type_str, epoch_ndx, isBest=False):\n",
    "        file_path = os.path.join(\n",
    "            'models',\n",
    "            self.cli_args.tb_prefix,\n",
    "            '{}_{}_{}.{}.state'.format(\n",
    "                type_str,\n",
    "                self.time_str,\n",
    "                self.cli_args.comment,\n",
    "                self.totalTrainingSamples_count,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        os.makedirs(os.path.dirname(file_path), mode=0o755, exist_ok=True)\n",
    "\n",
    "        model = self.segmentation_model\n",
    "        if isinstance(model, torch.nn.DataParallel):\n",
    "            model = model.module\n",
    "\n",
    "        state = {\n",
    "            'sys_argv': sys.argv,\n",
    "            'time': str(datetime.datetime.now()),\n",
    "            'model_state': model.state_dict(),\n",
    "            'model_name': type(model).__name__,\n",
    "            'optimizer_state' : self.optimizer.state_dict(),\n",
    "            'optimizer_name': type(self.optimizer).__name__,\n",
    "            'epoch': epoch_ndx,\n",
    "            'totalTrainingSamples_count': self.totalTrainingSamples_count,\n",
    "        }\n",
    "        torch.save(state, file_path)\n",
    "\n",
    "        log.info(\"Saved model params to {}\".format(file_path))\n",
    "\n",
    "        if isBest:\n",
    "            best_path = os.path.join(\n",
    "               'models',\n",
    "                self.cli_args.tb_prefix,\n",
    "                f'{type_str}_{self.time_str}_{self.cli_args.comment}.best.state')\n",
    "            shutil.copyfile(file_path, best_path)\n",
    "\n",
    "            log.info(\"Saved model params to {}\".format(best_path))\n",
    "\n",
    "        with open(file_path, 'rb') as f:\n",
    "            log.info(\"SHA1: \" + hashlib.sha1(f.read()).hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from segmentation import segment, init_segment_model\n",
    "# import SimpleITK as sitk\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# %matplotlib inline\n",
    "# data = sitk.ReadImage(\"C:/Users/oplab/Desktop/Luna16_data/Luna16_img/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260.mhd\")\n",
    "# # data = sitk.ReadImage(\"C:/Users/oplab/Desktop/Luna16_data/Luna16_img/subset8/1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222365663678666836860.mhd\")\n",
    "\n",
    "# ct_scan = sitk.GetArrayFromImage(data)\n",
    "# # result = segment(np.expand_dims(ct_scan[0:2], axis=0))\n",
    "# model, device = init_segment_model()\n",
    "# result = segment(ct_scan, model, device)\n",
    "# print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from nodule_segmentation import nodule_segment\n",
    "# import SimpleITK as sitk\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# %matplotlib inline\n",
    "# data = sitk.ReadImage(\"C:/Users/oplab/Desktop/Luna16_data/Luna16_img/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260.mhd\")\n",
    "# # data = sitk.ReadImage(\"C:/Users/oplab/Desktop/Luna16_data/Luna16_img/subset8/1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222365663678666836860.mhd\")\n",
    "\n",
    "# ct_scan = sitk.GetArrayFromImage(data)\n",
    "# # result = segment(np.expand_dims(ct_scan[0:2], axis=0))\n",
    "# # model, device = init_segment_model()\n",
    "# # result = segment(ct_scan, model, device)\n",
    "# result = nodule_segment(ct_scan)\n",
    "# print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def np2Png(np_arr, target_name):\n",
    "#     min_value = np.min(np_arr)\n",
    "#     max_value = np.max(np_arr)\n",
    "#     scaled_np_arr = (np_arr - min_value) / (max_value - min_value) * 255\n",
    "#     scaled_np_arr = scaled_np_arr.astype(np.uint8)\n",
    "#     slice_ori = Image.fromarray(scaled_np_arr, mode='L')\n",
    "#     slice_ori.save(target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(0, 2):\n",
    "#     np2Png(result[i].astype(float), \"./nodule_segment/test/{}_segmented.png\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(0, len(result)):\n",
    "#     np2Png(result[i].astype(float), \"./nodule_segment/test/{}_segmented.png\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(0, 121):\n",
    "#     np2Png(ct_scan[i].astype(float), \"./segment_test/origin/{}_origin.png\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from dsetsFullCT import ct_augment, ct_segment\n",
    "# import SimpleITK as sitk\n",
    "# data = sitk.ReadImage(\"C:/Users/oplab/Desktop/Luna16_data/Luna16_img/subset8/1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222365663678666836860.mhd\")\n",
    "# ct_scan = sitk.GetArrayFromImage(data)\n",
    "# augm = ct_augment(ct_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# segmented = ct_segment(augm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ds = Luna2dSegmentationDataset(series_uid = \"1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260\")\n",
    "# len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# augm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ct_scan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(0, 121):\n",
    "#     np2Png(ct_scan[i].astype(float), \"./augment_test/origin2/{}_origin.png\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(0, 241):\n",
    "#     np2Png(augm[i].astype(float), \"./augment_test/augmented2/{}_augmented.png\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:07:12,982 INFO     pid:23044 dsetsFullCT:363:__init__ <dsetsFullCT.TrainingLuna2dSegmentationDataset object at 0x000002129C350510>: 480 training series, 932 candidates, 14263 slices, 932 nodules\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932\n",
      "99 tensor(0.2889)\n",
      "199 tensor(0.5214)\n",
      "299 tensor(0.6427)\n",
      "399 tensor(0.7508)\n",
      "499 tensor(0.8096)\n",
      "599 tensor(1.1474)\n",
      "699 tensor(1.2220)\n",
      "799 tensor(1.3402)\n",
      "899 tensor(1.4048)\n",
      "tensor(1.4111)\n"
     ]
    }
   ],
   "source": [
    "train_ds = TrainingLuna2dSegmentationDataset(\n",
    "            val_stride=10,\n",
    "            set_class=\"Training\",\n",
    "            contextSlices_count=2,\n",
    "        )\n",
    "print(len(train_ds))\n",
    "p_count = 0\n",
    "n_count = 0\n",
    "total = (512 * 512)\n",
    "rate = 0\n",
    "for i, data in enumerate(train_ds):\n",
    "    p_count = data[1].sum()\n",
    "    n_count = total - p_count\n",
    "    rate += p_count/n_count\n",
    "    if (i + 1) % 100== 0:\n",
    "        print(i, rate)\n",
    "    if i == len(train_ds) - 1:\n",
    "        break\n",
    "print(rate)\n",
    "# train_ds[0][1].sum()\n",
    "# total_rate = 0\n",
    "# i = 0\n",
    "# average_rate = 0\n",
    "# for i in range(8001):\n",
    "#     # if (i % 10 == 0):\n",
    "#     #     # print(\"i = \", i)\n",
    "#     #     average_rate += (total_rate) / 10\n",
    "#     #     # print(\"avg = \", average_rate)\n",
    "#     #     total_rate = 0\n",
    "#     if (i % 1000 == 0):\n",
    "#         print(\"i = \", i)\n",
    "#         print(\"avg = \", average_rate)\n",
    "#     i += 1\n",
    "#     csum = (train_ds[i][1].sum())\n",
    "#     # print(\"sum = \", csum)\n",
    "#     total_rate += csum / total\n",
    "# average_rate = (total_rate) / 8000\n",
    "# print(average_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(660.4646)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / (rate / len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0015)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate / len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LunaPrepCacheApp(sys_argv=[\"--num-workers=0\"]).main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.autograd.set_detect_anomaly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import glob\n",
    "# import SimpleITK as sitk\n",
    "# import numpy as np\n",
    "# import collections\n",
    "# from PIL import Image, ImageDraw\n",
    "\n",
    "# train_ds = TrainingLuna2dSegmentationDataset(\n",
    "#             series_uid=\"1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222365663678666836860\"\n",
    "#         )\n",
    "# hu_a = train_ds[0][0].numpy()\n",
    "# hu_mask = train_ds[0][1].numpy().astype(int)\n",
    "# print(hu_a.shape)\n",
    "# print(hu_mask.shape)\n",
    "# min_value = np.min(hu_a[3])\n",
    "# max_value = np.max(hu_a[3])\n",
    "# scaled_hu_a = (hu_a[3] - min_value) / (max_value - min_value) * 255\n",
    "# scaled_hu_a = scaled_hu_a.astype(np.uint8)\n",
    "# slice_ori = Image.fromarray(scaled_hu_a, mode='L')\n",
    "# slice_ori.save(\"origin.png\")\n",
    "# min_value_mask = np.min(hu_mask[0])\n",
    "# max_value_mask = np.max(hu_mask[0])\n",
    "# # print(min_value_mask)\n",
    "# # print(max_value_mask)\n",
    "# scaled_mask = hu_mask[0] * 255\n",
    "# slice_mask = Image.fromarray(scaled_mask, mode='L')\n",
    "# slice_mask.save(\"mask.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = TrainingLuna2dSegmentationDataset(\n",
    "#             series_uid=\"1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222365663678666836860\"\n",
    "#         )\n",
    "# print(train_ds[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct_slice = Image.fromarray(scaled_hu_a, mode='L')\n",
    "\n",
    "# # Create a drawing context on the image\n",
    "# draw = ImageDraw.Draw(ct_slice)\n",
    "\n",
    "# # Define the coordinates to mark (row 212, column 45) as a red rectangle\n",
    "# x1, y1, x2, y2 = 44, 211, 46, 213  # Adjust these coordinates as needed\n",
    "\n",
    "# # Define the outline color as \"red\"\n",
    "# outline_color = (0, 0, 255)  # Use grayscale value 255 for white outline\n",
    "\n",
    "# # Draw a red rectangle on the image to mark the specific row and column\n",
    "# draw.rectangle([x1, y1, x2, y2], outline=\"white\", width=3)  # Increase width for better visibility\n",
    "\n",
    "# # Save the marked slice as a PNG\n",
    "# ct_slice.save(\"marked_slice.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation_model = UNetWrapper(\n",
    "#             in_channels=7,\n",
    "#             n_classes=1,\n",
    "#             depth=2,  #how deep the U go\n",
    "#             wf=6,   #2^4 filter\n",
    "#             padding=True, #padding so that we get the output size as input size\n",
    "#             batch_norm=True,\n",
    "#             up_mode='upconv', #use  nn.ConvTranspose2d\n",
    "#         )\n",
    "# # model_state\n",
    "# # torch.load(\"F:\\\\udet\\\\models\\\\udet\\\\seg_2023-10-19_08.28.18_final-cls.best.state\")[\"model_state\"]\n",
    "# segmentation_model.load_state_dict(torch.load(\"F:\\\\udet\\\\models\\\\udet\\\\u_net_depth2_200epcoch_f1score0.2.state\")[\"model_state\"])\n",
    "# device = torch.device(\"cuda\")\n",
    "# segmentation_model.to(device)\n",
    "# segmentation_model.eval()\n",
    "# val_ds = Luna2dSegmentationDataset(\n",
    "#             val_stride=10,\n",
    "#             isValSet_bool=True,\n",
    "#             contextSlices_count=3,\n",
    "#         )\n",
    "\n",
    "# batch_size = 8\n",
    "\n",
    "# val_dl = DataLoader(\n",
    "#     val_ds,\n",
    "#     batch_size=batch_size,\n",
    "#     num_workers=4,\n",
    "#     pin_memory=True,\n",
    "# )\n",
    "# batch_iter = enumerateWithEstimate(\n",
    "#     val_dl,\n",
    "#     \"E{} Validation \".format(1),\n",
    "#     start_ndx=val_dl.num_workers,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_ndx, batch_tup in batch_iter:\n",
    "#     input_t, label_t, series_list, _slice_ndx_list = batch_tup\n",
    "\n",
    "#     input_g = input_t.to(device, non_blocking=True)\n",
    "#     label_g = label_t.to(device, non_blocking=True)\n",
    "\n",
    "#     prediction_g = segmentation_model(input_g)\n",
    "#     np2Png(input_g.cpu().numpy().astype(int), \"./test/test.png\")\n",
    "#     np2Png(label_g.cpu().numpy().astype(int), \"./test/label.png\")\n",
    "#     np2Png(prediction_g.cpu().detach().numpy().astype(float), \"./test/predict.png\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val_ds = Luna2dSegmentationDataset(\n",
    "#             val_stride=1,\n",
    "#             isValSet_bool=True,\n",
    "#             contextSlices_count=0,\n",
    "#         )\n",
    "# print(len(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val_ds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(val_ds[0][0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(len(val_ds)):\n",
    "#     origin_n = val_ds[i][0].numpy()\n",
    "#     mask_n = val_ds[i][1].numpy()\n",
    "#     mask_ori_n = ((val_ds[i][0].float() + 1001) * val_ds[i][1]).numpy()\n",
    "#     # print(type(origin_n[0]))\n",
    "#     np2Png(origin_n.astype(int), \"./origin_new/{}_{}_{}.png\".format(i, val_ds[i][2], val_ds[i][3]))\n",
    "#     np2Png(mask_n.astype(int), \"./mask_new/{}_{}_{}.png\".format(i, val_ds[i][2], val_ds[i][3]))\n",
    "#     np2Png(mask_ori_n.astype(int), \"./mask_origin_new/{}_{}_{}.png\".format(i, val_ds[i][2], val_ds[i][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin_n = input_g.cpu().numpy()\n",
    "# np2Png(origin_n[0].astype(int), \"./test/test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prediction_g.size()\n",
    "# # label_g.size()\n",
    "# label_n = label_g.cpu().numpy()\n",
    "# np2Png(label_n[0].astype(int), \"./test/label.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_n = prediction_g.cpu().detach().numpy()\n",
    "# np2Png(prediction_n[0].astype(float), \"./test/predict.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_label_n = ((origin_n.astype(float) + 1001) * label_n)\n",
    "# np2Png(mask_label_n[0].astype(int), \"./test/mask_label.png\")\n",
    "# mask_pred_n = ((origin_n.astype(float) + 1001) * prediction_n)\n",
    "# np2Png(mask_pred_n[0].astype(int), \"./test/mask_pred.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(prediction_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prediction_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "hZFzy4E2Z6ui",
    "outputId": "39a224af-0945-456d-bdfc-7f1d6de7c73d"
   },
   "outputs": [],
   "source": [
    "# SegmentationTrainingApp(sys_argv=['--epochs=400','--augmented', 'final-cls',\"--num-workers=8\", \"--batch-size=16\"]).main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir E:\\LUNA\\nodule_detection\\runs\\p2ch13\\2023-08-17_12.51.58_val_seg_final-cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "vMbfUFaTZt05"
   },
   "outputs": [],
   "source": [
    "# run('p2ch13.training.SegmentationTrainingApp', f'--epochs={final_epochs}', '--augmented', 'final-cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "mnp0qlDFtjIL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SegmentationTrainingApp(sys_argv=['--epochs=1','--augmented', 'final-cls']).main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
